import os
import random
import numpy as np
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
from collections import Counter, defaultdict
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras import layers, models, regularizers

# ---------------------------
# Constants (adjust as needed)
# ---------------------------
DATA_DIR = '/kaggle/input/tomato-lef-disease-augmented/'  # change to your dataset path
BATCH_SIZE = 16
EPOCHS = 10
NUM_CLASSES = 4
FRAC_CLIENTS = 0.5
NUM_CLIENTS = 5
FED_ROUNDS = 10
SEED = 42

random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# ---------------------------
# Utility: load file paths & labels
# ---------------------------
def load_data(data_dir):
    images, labels = [], []
    class_names = sorted([c for c in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, c))])
    for label, class_name in enumerate(class_names):
        class_dir = os.path.join(data_dir, class_name)
        for img_name in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_name)
            if os.path.isfile(img_path):
                images.append(img_path)
                labels.append(label)
    images = np.array(images)
    labels = np.array(labels)
    return images, labels, class_names

# ---------------------------
# IID client splitter
# - Distributes each class' samples round-robin across clients,
#   which results in each client getting roughly the same class proportions.
# ---------------------------
def create_iid_clients(x, y, num_clients):
    per_class_indices = defaultdict(list)
    for idx, lbl in enumerate(y):
        per_class_indices[int(lbl)].append(idx)

    # shuffle indices per class
    for cls in per_class_indices:
        random.shuffle(per_class_indices[cls])

    clients_indices = [[] for _ in range(num_clients)]

    # round-robin distribution per class
    for cls, indices in per_class_indices.items():
        for i, idx in enumerate(indices):
            client_id = i % num_clients
            clients_indices[client_id].append(idx)

    # Convert indices to (paths, labels) tuples
    clients_data = []
    for inds in clients_indices:
        inds = sorted(inds)  # optional
        client_x = x[inds]
        client_y = y[inds]
        clients_data.append((client_x, client_y))

    return clients_data

# ---------------------------
# Generator to load images in batches from file paths
# ---------------------------
def image_generator(file_paths, labels, batch_size, shuffle=True):
    # file_paths, labels are arrays
    n = len(file_paths)
    indices = np.arange(n)
    while True:
        if shuffle:
            np.random.shuffle(indices)
        for start in range(0, n, batch_size):
            batch_idx = indices[start:start + batch_size]
            images = []
            batch_labels = []
            for i in batch_idx:
                try:
                    img = load_img(file_paths[i], target_size=(224, 224))
                    img = img_to_array(img) / 255.0
                    images.append(img)
                    batch_labels.append(labels[i])
                except Exception as e:
                    # skip problematic image but log once
                    print(f"Warning: couldn't load {file_paths[i]}: {str(e)}")
            if len(images) == 0:
                continue
            yield np.array(images), np.array(batch_labels)

# ---------------------------
# Model builder (ResNet50V2 base, frozen)
# ---------------------------
def create_custom_model(num_classes=NUM_CLASSES):
    base_model = ResNet50V2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
    base_model.trainable = False  # freeze
    x = base_model.output
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)
    x = layers.Dropout(0.5)(x)
    predictions = layers.Dense(num_classes, activation='softmax')(x)
    model = models.Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# ---------------------------
# Federated learning core
# ---------------------------
class FederatedLearning:
    def __init__(self, clients_data, num_classes=NUM_CLASSES):
        self.clients_data = clients_data
        self.num_clients = len(clients_data)
        self.global_model = create_custom_model(num_classes)
        self.global_weights = self.global_model.get_weights()

    def client_update(self, client_data):
        # clone model architecture and set weights to global
        model = tf.keras.models.clone_model(self.global_model)
        model.set_weights(self.global_weights)
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

        x_paths, y_labels = client_data
        steps_per_epoch = max(1, len(x_paths) // BATCH_SIZE)

        # create a small validation split from this client's data if possible
        if len(x_paths) < 10:
            # too small => train for fewer epochs or skip validation
            val_gen = None
            val_steps = None
        else:
            val_size = max(1, int(0.1 * len(x_paths)))
            x_val = x_paths[:val_size]
            y_val = y_labels[:val_size]
            val_gen = image_generator(x_val, y_val, BATCH_SIZE, shuffle=False)
            val_steps = max(1, len(x_val) // BATCH_SIZE)

        train_gen = image_generator(x_paths, y_labels, BATCH_SIZE, shuffle=True)

        history = model.fit(
            train_gen,
            steps_per_epoch=steps_per_epoch,
            epochs=EPOCHS,
            validation_data=val_gen,
            validation_steps=val_steps,
            verbose=1
        )

        return model.get_weights(), history.history

    @staticmethod
    def federated_averaging(client_weights):
        # average each weight tensor across clients
        averaged = []
        for weights_tuple in zip(*client_weights):
            averaged.append(np.mean(np.array(weights_tuple), axis=0))
        return averaged

    def train(self, rounds=FED_ROUNDS, frac_clients=FRAC_CLIENTS):
        # optional initial global training on the union of all client data (light)
        all_x = np.concatenate([c[0] for c in self.clients_data])
        all_y = np.concatenate([c[1] for c in self.clients_data])
        if len(all_x) >= BATCH_SIZE:
            print("Initial global pre-training on combined data (1 epoch)...")
            ensemble_gen = image_generator(all_x, all_y, BATCH_SIZE, shuffle=True)
            steps = max(1, len(all_x) // BATCH_SIZE)
            self.global_model.fit(ensemble_gen, steps_per_epoch=steps, epochs=1, verbose=1)
            self.global_weights = self.global_model.get_weights()

        for rnd in range(1, rounds + 1):
            print(f"\n=== Federated Round {rnd}/{rounds} ===")
            num_selected = max(1, int(frac_clients * self.num_clients))
            selected = np.random.choice(range(self.num_clients), size=num_selected, replace=False)
            client_weights = []
            val_losses = []
            val_accs = []

            for client_id in selected:
                print(f"-> Training client {client_id} (samples={len(self.clients_data[client_id][0])})")
                weights, history = self.client_update(self.clients_data[client_id])
                client_weights.append(weights)
                # record last validation metrics if present
                if 'val_loss' in history and len(history['val_loss']) > 0:
                    val_losses.append(history['val_loss'][-1])
                if 'val_accuracy' in history and len(history['val_accuracy']) > 0:
                    val_accs.append(history['val_accuracy'][-1])

            # average and update global weights
            if len(client_weights) > 0:
                self.global_weights = self.federated_averaging(client_weights)
                # set weights to the global model for next round
                self.global_model.set_weights(self.global_weights)

            if val_losses:
                print(f"Avg validation loss (selected clients): {np.mean(val_losses):.4f}")
            if val_accs:
                print(f"Avg validation accuracy (selected clients): {np.mean(val_accs):.4f}")

# ---------------------------
# Main flow: load -> split IID -> federated train -> evaluate
# ---------------------------
if __name__ == "__main__":
    # Load dataset
    image_paths, labels, class_names = load_data(DATA_DIR)
    print(f"Total images: {len(image_paths)}, classes: {class_names}")

    # Train/test split (global)
    x_train, x_test, y_train, y_test = train_test_split(
        image_paths, labels, test_size=0.2, random_state=SEED, stratify=labels
    )

    # Create IID clients
    clients_data = create_iid_clients(x_train, y_train, NUM_CLIENTS)
    for idx, (cx, cy) in enumerate(clients_data):
        cnt = Counter(cy)
        print(f"Client {idx}: samples={len(cx)}, class_dist={dict(cnt)}")

    # Optional: plot class distribution per client
    try:
        plt.figure(figsize=(12, 3 * NUM_CLIENTS // 2))
        for client_id, (cx, cy) in enumerate(clients_data):
            plt.subplot((NUM_CLIENTS + 1) // 2, 2, client_id + 1)
            dist = [Counter(cy).get(i, 0) for i in range(len(class_names))]
            bars = plt.bar(class_names, dist)
            plt.title(f'Client {client_id} class distribution')
            plt.xticks(rotation=45)
            for bar in bars:
                yval = bar.get_height()
                plt.text(bar.get_x() + bar.get_width() / 2, yval, int(yval), ha='center', va='bottom')
        plt.tight_layout()
        plt.show()
    except Exception as e:
        print(f"Could not plot distributions: {e}")

    # Initialize federated learning and train
    fed = FederatedLearning(clients_data, num_classes=len(class_names))
    fed.train(rounds=FED_ROUNDS, frac_clients=FRAC_CLIENTS)

    # ---------------------------
    # Evaluation on global test set
    # ---------------------------
    print("\nEvaluating global model on held-out test set...")
    # Build a fresh model and set the federated-learned weights
    test_model = create_custom_model(num_classes=len(class_names))
    test_model.set_weights(fed.global_weights)

    test_gen = image_generator(x_test, y_test, BATCH_SIZE, shuffle=False)
    num_steps = (len(x_test) + BATCH_SIZE - 1) // BATCH_SIZE

    y_pred = []
    y_true = []

    for _ in range(num_steps):
        batch_x, batch_y = next(test_gen)
        preds = test_model.predict(batch_x, verbose=0)
        y_pred.extend(np.argmax(preds, axis=1))
        y_true.extend(batch_y)

    y_pred = np.array(y_pred)
    y_true = np.array(y_true)

    # If there's extra padding or mismatch, trim to smallest length
    if len(y_pred) != len(y_true):
        minlen = min(len(y_pred), len(y_true))
        y_pred = y_pred[:minlen]
        y_true = y_true[:minlen]

    test_acc = np.mean(y_pred == y_true)
    print(f"Test Accuracy: {test_acc:.4f}")

    # Classification report
    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=45)
    plt.yticks(tick_marks, class_names)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5
    for i, j in np.ndindex(cm.shape):
        plt.text(j, i, format(cm[i, j], 'd'),
                 ha="center", va="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.show()
